{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of shonenkov-training-pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Morphling89/CNNs/blob/master/Copy_of_shonenkov_training_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsZb7QICuRIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "6f9068d7-7ded-406f-ef34-e22e4dea6051"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py > /dev/null\n",
        "!python pytorch-xla-env-setup.py --version 20200601 --apt-packages libomp5 libopenblas-dev > /dev/null\n",
        "!pip install transformers==2.5.1 > /dev/null\n",
        "!pip install pandarallel > /dev/null\n",
        "!pip install catalyst==20.4.2 > /dev/null"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  4264  100  4264    0     0  25380      0 --:--:-- --:--:-- --:--:-- 25380\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200601-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 90.2 MiB/ 90.2 MiB]                                                \n",
            "Operation completed over 1 objects/90.2 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200601-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][121.3 MiB/121.3 MiB]                                                \n",
            "Operation completed over 1 objects/121.3 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200601-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.1 MiB/  2.1 MiB]                                                \n",
            "Operation completed over 1 objects/2.1 MiB.                                      \n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjgueEURZ_nV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0755c78f-95a5-4100-93e3-d9c1cf5e7b92"
      },
      "source": [
        "!pip install iterative-stratification\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: iterative-stratification in /usr/local/lib/python3.6/dist-packages (0.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->iterative-stratification) (0.15.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6uGvKL3upio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "df02db6d-cf8b-4ddc-ba96-4629bf934d78"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "\n",
        "import os,shutil\n",
        "os.environ['XLA_USE_BF16'] = \"1\"\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
        "import sklearn\n",
        "\n",
        "import time\n",
        "import random\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from transformers import XLMRobertaModel, XLMRobertaTokenizer,XLMRobertaConfig\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n",
        "from catalyst.data.sampler import DistributedSamplerWrapper, BalanceClassSampler\n",
        "# import tensorflow as tf\n",
        "import gc\n",
        "import re\n",
        "\n",
        "# !pip install nltk > /dev/null\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "from pandarallel import pandarallel\n",
        "\n",
        "pandarallel.initialize(nb_workers=4, progress_bar=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
            "\n",
            "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "INFO: Pandarallel will run on 4 workers.\n",
            "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YkINClnSOto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "#   print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "# else:\n",
        "#   tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "#   print ('TPU address is', tpu_address)\n",
        "# tf.config.experimental_connect_to_host(tpu_address)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_NBlA99aJSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %tensorflow_version 1.x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFAF3E5AZTT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(tf.__version__)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6GqhJ5tSfpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n",
        "# tf.tpu.experimental.initialize_tpu_system(cluster_resolver)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-VP4QbZu9EB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "MAX_LENGTH = 224\n",
        "BACKBONE_PATH = 'xlm-roberta-large'\n",
        "# ROOT_PATH = f'..'\n",
        "ROOT_PATH = f'/content/drive/My Drive/Colab Notebooks/toxic_multi' # for colab\n",
        "CHECKPOINT_PATH = f'/content/drive/My Drive/Colab Notebooks/toxic_multi/results'\n",
        "\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(SEED)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63ceMzcxu9GS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9a9dbc57-8515-499e-febe-3290dcde3def"
      },
      "source": [
        "from nltk import sent_tokenize\n",
        "from random import shuffle\n",
        "import random\n",
        "import albumentations\n",
        "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
        "\n",
        "\n",
        "LANGS = {\n",
        "    'en': 'english',\n",
        "    'it': 'italian', \n",
        "    'fr': 'french', \n",
        "    'es': 'spanish',\n",
        "    'tr': 'turkish', \n",
        "    'ru': 'russian',\n",
        "    'pt': 'portuguese'\n",
        "}\n",
        "\n",
        "def get_sentences(text, lang='en'):\n",
        "    return sent_tokenize(text, LANGS.get(lang, 'english'))\n",
        "\n",
        "def exclude_duplicate_sentences(text, lang='en'):\n",
        "    sentences = []\n",
        "    for sentence in get_sentences(text, lang):\n",
        "        sentence = sentence.strip()\n",
        "        if sentence not in sentences:\n",
        "            sentences.append(sentence)\n",
        "    return ' '.join(sentences)\n",
        "\n",
        "def clean_text(text, lang='en'):\n",
        "    text = str(text)\n",
        "    text = re.sub(r'[0-9\"]', '', text)\n",
        "    text = re.sub(r'#[\\S]+\\b', '', text)\n",
        "    text = re.sub(r'@[\\S]+\\b', '', text)\n",
        "    text = re.sub(r'https?\\S+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = exclude_duplicate_sentences(text, lang)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "class NLPTransform(BasicTransform):\n",
        "    \"\"\" Transform for nlp task.\"\"\"\n",
        "\n",
        "    @property\n",
        "    def targets(self):\n",
        "        return {\"data\": self.apply}\n",
        "    \n",
        "    def update_params(self, params, **kwargs):\n",
        "        if hasattr(self, \"interpolation\"):\n",
        "            params[\"interpolation\"] = self.interpolation\n",
        "        if hasattr(self, \"fill_value\"):\n",
        "            params[\"fill_value\"] = self.fill_value\n",
        "        return params\n",
        "\n",
        "    def get_sentences(self, text, lang='en'):\n",
        "        return sent_tokenize(text, LANGS.get(lang, 'english'))\n",
        "\n",
        "class ShuffleSentencesTransform(NLPTransform):\n",
        "    \"\"\" Do shuffle by sentence \"\"\"\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(ShuffleSentencesTransform, self).__init__(always_apply, p)\n",
        "\n",
        "    def apply(self, data, **params):\n",
        "        text, lang = data\n",
        "        sentences = self.get_sentences(text, lang)\n",
        "        random.shuffle(sentences)\n",
        "        return ' '.join(sentences), lang\n",
        "\n",
        "class ExcludeDuplicateSentencesTransform(NLPTransform):\n",
        "    \"\"\" Exclude equal sentences \"\"\"\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(ExcludeDuplicateSentencesTransform, self).__init__(always_apply, p)\n",
        "\n",
        "    def apply(self, data, **params):\n",
        "        text, lang = data\n",
        "        sentences = []\n",
        "        for sentence in self.get_sentences(text, lang):\n",
        "            sentence = sentence.strip()\n",
        "            if sentence not in sentences:\n",
        "                sentences.append(sentence)\n",
        "        return ' '.join(sentences), lang\n",
        "\n",
        "class ExcludeNumbersTransform(NLPTransform):\n",
        "    \"\"\" exclude any numbers \"\"\"\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(ExcludeNumbersTransform, self).__init__(always_apply, p)\n",
        "\n",
        "    def apply(self, data, **params):\n",
        "        text, lang = data\n",
        "        text = re.sub(r'[0-9]', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return text, lang\n",
        "\n",
        "class ExcludeHashtagsTransform(NLPTransform):\n",
        "    \"\"\" Exclude any hashtags with # \"\"\"\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(ExcludeHashtagsTransform, self).__init__(always_apply, p)\n",
        "\n",
        "    def apply(self, data, **params):\n",
        "        text, lang = data\n",
        "        text = re.sub(r'#[\\S]+\\b', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return text, lang\n",
        "\n",
        "class ExcludeUsersMentionedTransform(NLPTransform):\n",
        "    \"\"\" Exclude @users \"\"\"\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(ExcludeUsersMentionedTransform, self).__init__(always_apply, p)\n",
        "\n",
        "    def apply(self, data, **params):\n",
        "        text, lang = data\n",
        "        text = re.sub(r'@[\\S]+\\b', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return text, lang\n",
        "\n",
        "class ExcludeUrlsTransform(NLPTransform):\n",
        "    \"\"\" Exclude urls \"\"\"\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(ExcludeUrlsTransform, self).__init__(always_apply, p)\n",
        "\n",
        "    def apply(self, data, **params):\n",
        "        text, lang = data\n",
        "        text = re.sub(r'https?\\S+', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return text, lang"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
            "\n",
            "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFB3UeyAsYCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SynthesicOpenSubtitlesTransform(NLPTransform):\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(SynthesicOpenSubtitlesTransform, self).__init__(always_apply, p)\n",
        "        df = pd.read_csv(f'{ROOT_PATH}/input/open-subtitles-synthesic.csv', index_col='id')[['comment_text', 'toxic', 'lang']]\n",
        "        df = df[~df['comment_text'].isna()]\n",
        "        df['comment_text'] = df.parallel_apply(lambda x: clean_text(x['comment_text'], x['lang']), axis=1)\n",
        "        df = df.drop_duplicates(subset='comment_text')\n",
        "        df['toxic'] = df['toxic'].round().astype(np.int)\n",
        "\n",
        "        self.synthesic_toxic = df[df['toxic'] == 1].comment_text.values\n",
        "        self.synthesic_non_toxic = df[df['toxic'] == 0].comment_text.values\n",
        "\n",
        "        del df\n",
        "        gc.collect();\n",
        "\n",
        "    def generate_synthesic_sample(self, text, toxic):\n",
        "        texts = [text]\n",
        "        if toxic == 0:\n",
        "            for i in range(random.randint(1,5)):\n",
        "                texts.append(random.choice(self.synthesic_non_toxic))\n",
        "        else:\n",
        "            for i in range(random.randint(0,2)):\n",
        "                texts.append(random.choice(self.synthesic_non_toxic))\n",
        "            \n",
        "            for i in range(random.randint(1,3)):\n",
        "                texts.append(random.choice(self.synthesic_toxic))\n",
        "        random.shuffle(texts)\n",
        "        return ' '.join(texts)\n",
        "\n",
        "    def apply(self, data, **params):\n",
        "        text, toxic = data\n",
        "        text = self.generate_synthesic_sample(text, toxic)\n",
        "        return text, toxic"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5BdJ9HWvnLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_transforms():\n",
        "    return albumentations.Compose([\n",
        "        ExcludeUsersMentionedTransform(p=0.95),\n",
        "        ExcludeUrlsTransform(p=0.95),\n",
        "        ExcludeNumbersTransform(p=0.95),\n",
        "        ExcludeHashtagsTransform(p=0.95),\n",
        "        ExcludeDuplicateSentencesTransform(p=0.95),\n",
        "    ], p=1.0)\n",
        "\n",
        "def get_synthesic_transforms():\n",
        "    return SynthesicOpenSubtitlesTransform(p=0.5)\n",
        "\n",
        "\n",
        "train_transforms = get_train_transforms();\n",
        "synthesic_transforms = get_synthesic_transforms()\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(BACKBONE_PATH)\n",
        "shuffle_transforms = ShuffleSentencesTransform(always_apply=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFp80AuJu9Ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def onehot(size, target):\n",
        "    vec = torch.zeros(size, dtype=torch.float32)\n",
        "    vec[target] = 1.\n",
        "    return vec\n",
        "\n",
        "class DatasetRetriever(Dataset):\n",
        "\n",
        "    def __init__(self, labels_or_ids, comment_texts, langs, use_train_transforms=False, test=False):\n",
        "        self.test = test\n",
        "        self.labels_or_ids = labels_or_ids\n",
        "        self.comment_texts = comment_texts\n",
        "        self.langs = langs\n",
        "        self.use_train_transforms = use_train_transforms\n",
        "        \n",
        "    def get_tokens(self, text):\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            text, \n",
        "            add_special_tokens=True, \n",
        "            max_length=MAX_LENGTH, \n",
        "            pad_to_max_length=True\n",
        "        )\n",
        "        return encoded['input_ids'], encoded['attention_mask']\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.comment_texts.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comment_texts[idx]\n",
        "        lang = self.langs[idx]\n",
        "        if self.test is False:\n",
        "            label = self.labels_or_ids[idx]\n",
        "            target = onehot(2, label)\n",
        "\n",
        "        if self.use_train_transforms:\n",
        "            text, _ = train_transforms(data=(text, lang))['data']\n",
        "            tokens, attention_mask = self.get_tokens(str(text))\n",
        "            token_length = sum(attention_mask)\n",
        "            if token_length > 0.8*MAX_LENGTH:\n",
        "                text, _ = shuffle_transforms(data=(text, lang))['data']\n",
        "            elif token_length < 60:\n",
        "                text, _ = synthesic_transforms(data=(text, label))['data']\n",
        "            else:\n",
        "                tokens, attention_mask = torch.tensor(tokens), torch.tensor(attention_mask)\n",
        "                return target, tokens, attention_mask\n",
        "\n",
        "        tokens, attention_mask = self.get_tokens(str(text))\n",
        "        tokens, attention_mask = torch.tensor(tokens), torch.tensor(attention_mask)\n",
        "\n",
        "        if self.test is False:\n",
        "            return target, tokens, attention_mask\n",
        "        return self.labels_or_ids[idx], tokens, attention_mask\n",
        "\n",
        "    def get_labels(self):\n",
        "        return list(np.char.add(self.labels_or_ids.astype(str), self.langs))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DVkkUVMu9Ka",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "f88c4d03-665c-4dc3-ab24-6d0457743eac"
      },
      "source": [
        "%%time\n",
        "\n",
        "df_train = pd.read_csv(f'{ROOT_PATH}/input/train_data.csv')\n",
        "\n",
        "df_train_3 = pd.read_csv(f'{ROOT_PATH}/input/unintended-bias_multi_0.25_train_data.csv').sample(500000,random_state=42)\n",
        "\n",
        "df_train_2 = pd.read_csv(f'{ROOT_PATH}/input/jigsaw1test_trans.csv').rename(columns = {'en':'comment_text'})\n",
        "df_train_2['lang']='en'\n",
        "# df_train_2 = pd.read_csv(f'{ROOT_PATH}/input/external_multilan_toxic_data.csv').rename(columns = {'clean_text':'comment_text'})\n",
        "df_train = pd.concat((df_train,df_train_2,df_train_3)).reset_index(drop=True)\n",
        "\n",
        "train_dataset = DatasetRetriever(\n",
        "    labels_or_ids=df_train['toxic'].values, \n",
        "    comment_texts=df_train['comment_text'].values, \n",
        "    langs=df_train['lang'].values,\n",
        "    use_train_transforms=True,\n",
        ")\n",
        "\n",
        "del df_train\n",
        "gc.collect();\n",
        "\n",
        "for targets, tokens, attention_masks in train_dataset:\n",
        "    break\n",
        "    \n",
        "print(targets)\n",
        "print(tokens.shape)\n",
        "print(attention_masks.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:2: DtypeWarning:\n",
            "\n",
            "Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 0.])\n",
            "torch.Size([224])\n",
            "torch.Size([224])\n",
            "CPU times: user 36.6 s, sys: 4.29 s, total: 40.9 s\n",
            "Wall time: 43 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FML5BrtD1R9J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55801193-3ada-4380-f8d5-240057597da4"
      },
      "source": [
        "len(train_dataset)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3995557"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlcGdUdSYewm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d733372f-99b4-440f-d27d-c7a45fb96bb0"
      },
      "source": [
        "np.unique(train_dataset.get_labels())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0en', '0es', '0fr', '0it', '0pt', '0ru', '0tr', '1en', '1es',\n",
              "       '1fr', '1it', '1pt', '1ru', '1tr'], dtype='<U3')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgku5zEfZLvW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "efd734d9-e57a-4d08-a0eb-2d42b193f884"
      },
      "source": [
        "NFOLD = 4\n",
        "SEED = 42\n",
        "kf = MultilabelStratifiedKFold(n_splits=NFOLD, shuffle=True, random_state=SEED)\n",
        "val_train_fd={}\n",
        "val_train_en_fd={}\n",
        "\n",
        "val_valid_fd={}\n",
        "val_valid_en_fd={}\n",
        "\n",
        "val_inf_fd = {}\n",
        "val_en_inf_fd = {}\n",
        "\n",
        "\n",
        "df_val = pd.read_csv(f'{ROOT_PATH}/input/validation.csv', index_col='id')\n",
        "df_val['comment_text'] = df_val.parallel_apply(lambda x: clean_text(x['comment_text'], x['lang']), axis=1)\n",
        "df_val_en = pd.read_csv(f'{ROOT_PATH}/input/validation_en.csv', index_col='id')\n",
        "df_val_en['lang']='en'\n",
        "df_val_en['comment_text'] = df_val_en.parallel_apply(lambda x: clean_text(x['comment_text_en'], x['lang']), axis=1)\n",
        "\n",
        "for fold, (trn_idx, val_idx) in enumerate(kf.split(X=df_val,y=df_val[['lang','toxic']].values)):\n",
        "  df_val_train = df_val.loc[trn_idx].dropna()\n",
        "  df_val_test = df_val.loc[val_idx].dropna()\n",
        "  df_val_train_en = df_val_en.loc[trn_idx].dropna()\n",
        "  df_val_test_en = df_val_en.loc[val_idx].dropna()\n",
        "  validation_train_dataset = DatasetRetriever(\n",
        "      labels_or_ids=df_val_train[['toxic']].values, \n",
        "      comment_texts=df_val_train['comment_text'].values, \n",
        "      langs=df_val_train['lang'].values,\n",
        "      use_train_transforms=True,\n",
        "  )\n",
        "  validation_train_en_dataset = DatasetRetriever(\n",
        "      labels_or_ids=df_val_train_en[['toxic']].values, \n",
        "      comment_texts=df_val_train_en['comment_text'].values, \n",
        "      langs=df_val_train_en['lang'].values,\n",
        "      use_train_transforms=True,\n",
        "  )\n",
        "  validation_test_dataset = DatasetRetriever(\n",
        "      labels_or_ids=df_val_test[['toxic']].values, \n",
        "      comment_texts=df_val_test['comment_text'].values, \n",
        "      langs=df_val_test['lang'].values,\n",
        "      use_train_transforms=True,\n",
        "  )\n",
        "  validation_test_en_dataset = DatasetRetriever(\n",
        "      labels_or_ids=df_val_test_en[['toxic']].values, \n",
        "      comment_texts=df_val_test_en['comment_text'].values, \n",
        "      langs=df_val_train_en['lang'].values,\n",
        "      use_train_transforms=True,\n",
        "  )\n",
        "  validation_infer_dataset = DatasetRetriever(\n",
        "      labels_or_ids=df_val_test.index.values, \n",
        "      comment_texts=df_val_test['comment_text'].values, \n",
        "      langs=df_val_test['lang'].values,\n",
        "      use_train_transforms=False,\n",
        "      test=True\n",
        "  )\n",
        "  validation_infer_en_dataset = DatasetRetriever(\n",
        "      labels_or_ids=df_val_test_en.index.values, \n",
        "      comment_texts=df_val_test_en['comment_text'].values, \n",
        "      langs=df_val_test_en['lang'].values,\n",
        "      use_train_transforms=False,\n",
        "      test=True\n",
        "  )\n",
        "  val_train_en_fd[fold] = validation_train_en_dataset\n",
        "  val_train_fd[fold] = validation_train_dataset\n",
        "\n",
        "  val_inf_fd[fold] = validation_infer_dataset\n",
        "  val_en_inf_fd[fold] = validation_infer_en_dataset\n",
        "\n",
        "  val_valid_fd[fold] = validation_test_dataset\n",
        "  val_valid_en_fd[fold] = validation_test_en_dataset\n",
        "\n",
        "\n",
        "  print(f'fold {fold} train len is {len(validation_train_dataset)}, test len is {len(validation_test_dataset)}')\n",
        "# df_val = pd.read_csv(f'{ROOT_PATH}/input/train_data_moreAttr.csv')\n",
        "# df_val = df_val[(df_val['fold']==0) & (df_val['lang']!='en')].reset_index(drop=True)\n",
        "validation_tune_dataset = DatasetRetriever(\n",
        "    labels_or_ids=df_val[['toxic']].values, \n",
        "    comment_texts=df_val['comment_text'].values, \n",
        "    langs=df_val['lang'].values,\n",
        "    use_train_transforms=True,\n",
        ")\n",
        "\n",
        "validation_all_infer_dataset = DatasetRetriever(\n",
        "    labels_or_ids=df_val.index.values, \n",
        "    comment_texts=df_val['comment_text'].values, \n",
        "    langs=df_val['lang'].values,\n",
        "    use_train_transforms=False,\n",
        "    test=True\n",
        ")\n",
        "validation_dataset = DatasetRetriever(\n",
        "    labels_or_ids=df_val[['toxic']].values, \n",
        "    comment_texts=df_val['comment_text'].values, \n",
        "    langs=df_val['lang'].values,\n",
        "    use_train_transforms=False,\n",
        ")\n",
        "\n",
        "\n",
        "del df_val,df_val_train,df_val_test\n",
        "gc.collect();\n",
        "\n",
        "for targets, tokens, attention_masks in validation_dataset:\n",
        "    break\n",
        "\n",
        "print(targets)\n",
        "print(tokens.shape)\n",
        "print(attention_masks.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 0 train len is 6000, test len is 2000\n",
            "fold 1 train len is 6000, test len is 2000\n",
            "fold 2 train len is 6000, test len is 2000\n",
            "fold 3 train len is 6000, test len is 2000\n",
            "tensor([1., 0.])\n",
            "torch.Size([224])\n",
            "torch.Size([224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW4dEWaYu9NF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_val = pd.read_csv(f'{ROOT_PATH}/input/validation.csv', index_col='id')\n",
        "\n",
        "# validation_tune_dataset = DatasetRetriever(\n",
        "#     labels_or_ids=df_val['toxic'].values, \n",
        "#     comment_texts=df_val['comment_text'].values, \n",
        "#     langs=df_val['lang'].values,\n",
        "#     use_train_transforms=True,\n",
        "# )\n",
        "\n",
        "# df_val['comment_text'] = df_val.parallel_apply(lambda x: clean_text(x['comment_text'], x['lang']), axis=1)\n",
        "\n",
        "# validation_dataset = DatasetRetriever(\n",
        "#     labels_or_ids=df_val['toxic'].values, \n",
        "#     comment_texts=df_val['comment_text'].values, \n",
        "#     langs=df_val['lang'].values,\n",
        "#     use_train_transforms=False,\n",
        "# )\n",
        "\n",
        "# del df_val\n",
        "# gc.collect();\n",
        "\n",
        "# for targets, tokens, attention_masks in validation_dataset:\n",
        "#     break\n",
        "\n",
        "# print(targets)\n",
        "# print(tokens.shape)\n",
        "# print(attention_masks.shape)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNdADp28v3av",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1ebc19ac-03f0-447f-8675-3de663f1fc15"
      },
      "source": [
        "df_test = pd.read_csv(f'{ROOT_PATH}/input/test.csv', index_col='id')\n",
        "df_test['comment_text'] = df_test.parallel_apply(lambda x: clean_text(x['content'], x['lang']), axis=1)\n",
        "\n",
        "test_dataset = DatasetRetriever(\n",
        "    labels_or_ids=df_test.index.values, \n",
        "    comment_texts=df_test['comment_text'].values, \n",
        "    langs=df_test['lang'].values,\n",
        "    use_train_transforms=False,\n",
        "    test=True\n",
        ")\n",
        "\n",
        "del df_test\n",
        "gc.collect();\n",
        "\n",
        "for ids, tokens, attention_masks in test_dataset:\n",
        "    break\n",
        "\n",
        "print(ids)\n",
        "print(tokens.shape)\n",
        "print(attention_masks.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "torch.Size([224])\n",
            "torch.Size([224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olMWv3A5kDc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "012979cc-4f1e-4b02-f680-75bd33881f20"
      },
      "source": [
        "df_test_en = pd.read_csv(f'{ROOT_PATH}/input/test_en.csv', index_col='id')\n",
        "df_test_en['lang'] = 'en'\n",
        "df_test_en['comment_text'] = df_test_en.parallel_apply(lambda x: clean_text(x['content_en'], x['lang']), axis=1)\n",
        "\n",
        "test_en_dataset = DatasetRetriever(\n",
        "    labels_or_ids=df_test_en.index.values, \n",
        "    comment_texts=df_test_en['comment_text'].values, \n",
        "    langs=df_test_en['lang'].values,\n",
        "    use_train_transforms=False,\n",
        "    test=True\n",
        ")\n",
        "\n",
        "del df_test_en\n",
        "gc.collect();\n",
        "\n",
        "for ids, tokens, attention_masks in test_en_dataset:\n",
        "    break\n",
        "\n",
        "print(ids)\n",
        "print(tokens.shape)\n",
        "print(attention_masks.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "torch.Size([224])\n",
            "torch.Size([224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2bN_NySwU6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RocAucMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.y_true = np.array([0,1])\n",
        "        self.y_pred = np.array([0.5,0.5])\n",
        "        self.score = 0\n",
        "\n",
        "    def update(self, y_true, y_pred):\n",
        "        y_true = y_true.cpu().numpy().argmax(axis=1)\n",
        "        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n",
        "        self.y_true = np.hstack((self.y_true, y_true))\n",
        "        self.y_pred = np.hstack((self.y_pred, y_pred))\n",
        "        self.score = sklearn.metrics.roc_auc_score(self.y_true, self.y_pred, labels=np.array([0, 1]))\n",
        "    \n",
        "    @property\n",
        "    def avg(self):\n",
        "        return self.score\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arcC5IeYxUbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0bdf55e7-613f-48e3-a567-4a17e83df5c2"
      },
      "source": [
        "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
        "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
        "      per_image: compute the loss per image instead of per batch\n",
        "      ignore: void class id\n",
        "    \"\"\"\n",
        "    if per_image:\n",
        "        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n",
        "                          for log, lab in zip(logits, labels))\n",
        "    else:\n",
        "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def lovasz_hinge_flat(logits, labels):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
        "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
        "      ignore: label to ignore\n",
        "    \"\"\"\n",
        "    if len(labels) == 0:\n",
        "        # only void pixels, the gradients should be 0\n",
        "        return logits.sum() * 0.\n",
        "    signs = 2. * labels.float() - 1.\n",
        "    errors = (1. - logits * Variable(signs))\n",
        "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
        "    perm = perm.data\n",
        "    gt_sorted = labels[perm]\n",
        "    grad = lovasz_grad(gt_sorted)\n",
        "    loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n",
        "    return loss\n",
        "\n",
        "class LabelSmoothing(nn.Module):\n",
        "    def __init__(self, smoothing = 0.1):\n",
        "        super(LabelSmoothing, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        if self.training:\n",
        "            x = x.float()\n",
        "            target = target.float()\n",
        "            logprobs = torch.nn.functional.log_softmax(x, dim = -1)\n",
        "\n",
        "            nll_loss = -logprobs * target\n",
        "            nll_loss = nll_loss.sum(-1)\n",
        "    \n",
        "            smooth_loss = -logprobs.mean(dim=-1)\n",
        "\n",
        "            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
        "\n",
        "            return loss.mean()\n",
        "        else:\n",
        "            return torch.nn.functional.cross_entropy(x, target)\n",
        "\n",
        "class LabelSmoothinglovasz(nn.Module):\n",
        "    def __init__(self, smoothing = 0.1):\n",
        "        super(LabelSmoothing, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, x, target,):\n",
        "        if self.training:\n",
        "            x = x.float()\n",
        "            target = target.float()\n",
        "            logprobs = torch.nn.functional.log_softmax(x, dim = -1)\n",
        "\n",
        "            nll_loss = -logprobs * target\n",
        "            nll_loss = nll_loss.sum(-1)\n",
        "    \n",
        "            smooth_loss = -logprobs.mean(dim=-1)\n",
        "\n",
        "            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
        "\n",
        "            return loss.mean()\n",
        "        else:\n",
        "            return torch.nn.functional.cross_entropy(x, target)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<input>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n",
            "<ipython-input-16-823f6cdec3bd>:8: DeprecationWarning:\n",
            "\n",
            "invalid escape sequence \\i\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow13PTlFwbiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "\n",
        "from catalyst.data.sampler import DistributedSamplerWrapper, BalanceClassSampler\n",
        "\n",
        "class TPUFitter:\n",
        "    \n",
        "    def __init__(self, model, device, config):\n",
        "        if not os.path.exists(f'{CHECKPOINT_PATH}/node_submissions'):\n",
        "            os.makedirs(f'{CHECKPOINT_PATH}/node_submissions')\n",
        "\n",
        "        self.config = config\n",
        "        self.epoch = 0\n",
        "        self.log_path = f'{CHECKPOINT_PATH}/log.txt'\n",
        "\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        xm.master_print(f'Model prepared. Device is {self.device}')\n",
        "        \n",
        "        param_optimizer = list(self.model.named_parameters())\n",
        "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
        "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "\n",
        "        self.optimizer = AdamW(optimizer_grouped_parameters, lr=config.lr*xm.xrt_world_size())\n",
        "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
        "\n",
        "        self.criterion = config.criterion\n",
        "        xm.master_print(f'Fitter prepared. Device is {self.device}')\n",
        "\n",
        "    def fit(self, train_loader, validation_loader):\n",
        "        best_score = 0.95096\n",
        "        for e in range(self.config.n_epochs):\n",
        "            if self.config.verbose:\n",
        "                lr = self.optimizer.param_groups[0]['lr']\n",
        "                timestamp = datetime.utcnow().isoformat()\n",
        "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
        "\n",
        "            t = time.time()\n",
        "            para_loader = pl.ParallelLoader(train_loader, [self.device])\n",
        "            losses, final_scores = self.train_one_epoch(para_loader.per_device_loader(self.device))\n",
        "            self.model.eval()\n",
        "            self.save(f'{CHECKPOINT_PATH}/last-checkpoint.bin')            \n",
        "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, loss: {losses.avg:.5f}, final_score: {final_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n",
        "\n",
        "            t = time.time()\n",
        "            para_loader = pl.ParallelLoader(validation_loader, [self.device])\n",
        "            losses, final_scores = self.validation(para_loader.per_device_loader(self.device))\n",
        "            if final_scores.avg > best_score:\n",
        "              best_score = final_scores.avg\n",
        "              self.log(f'best score with {best_score}')\n",
        "              self.save(f'{CHECKPOINT_PATH}/best_model.bin')\n",
        "            self.log(f'[RESULT]: Validation. Epoch: {self.epoch}, loss: {losses.avg:.5f}, final_score: {final_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n",
        "\n",
        "            if self.config.validation_scheduler:\n",
        "                self.scheduler.step(metrics=final_scores.avg)\n",
        "\n",
        "            self.epoch += 1\n",
        "    def fit_valid(self, train_loader, validation_loader,fold):\n",
        "        best_score = 0\n",
        "        self.log(f'training fold {fold}\\n')\n",
        "        for e in range(self.config.valid_n_epochs):\n",
        "            if self.config.verbose:\n",
        "                lr = self.optimizer.param_groups[1]['lr']\n",
        "                timestamp = datetime.utcnow().isoformat()\n",
        "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
        "\n",
        "            t = time.time()\n",
        "            para_loader = pl.ParallelLoader(train_loader, [self.device])\n",
        "            losses, final_scores = self.train_one_epoch(para_loader.per_device_loader(self.device),mode='valid')\n",
        "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, loss: {losses.avg:.5f}, final_score: {final_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n",
        "\n",
        "            self.model.eval()\n",
        "            # self.save(f'{CHECKPOINT_PATH}/last-checkpoint.bin')\n",
        "\n",
        "            t = time.time()\n",
        "            para_loader = pl.ParallelLoader(validation_loader, [self.device])\n",
        "            losses, final_scores = self.validation(para_loader.per_device_loader(self.device))\n",
        "\n",
        "            if final_scores.avg > best_score:\n",
        "              best_score = final_scores.avg\n",
        "              self.log(f'best score with {best_score} for {fold}')\n",
        "              # self.save(f'{CHECKPOINT_PATH}/{fold}_best_model.bin')\n",
        "\n",
        "            self.log(f'[RESULT]: Validation. Epoch: {self.epoch}, loss: {losses.avg:.5f}, final_score: {final_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n",
        "\n",
        "            if self.config.validation_scheduler:\n",
        "                self.scheduler.step(metrics=final_scores.avg)\n",
        "\n",
        "            self.epoch += 1   \n",
        "    def run_tuning_and_inference(self, test_loader, validation_tune_loader):\n",
        "        for e in range(2):\n",
        "            self.optimizer.param_groups[0]['lr'] = self.config.lr*xm.xrt_world_size()\n",
        "            para_loader = pl.ParallelLoader(validation_tune_loader, [self.device])\n",
        "            losses, final_scores = self.train_one_epoch(para_loader.per_device_loader(self.device),mode='valid')\n",
        "            para_loader = pl.ParallelLoader(test_loader, [self.device])\n",
        "            self.run_inference(para_loader.per_device_loader(self.device))\n",
        "\n",
        "    def validation(self, val_loader):\n",
        "        self.model.eval()\n",
        "        losses = AverageMeter()\n",
        "        final_scores = RocAucMeter()\n",
        "\n",
        "        t = time.time()\n",
        "        for step, (targets, inputs, attention_masks) in enumerate(val_loader):\n",
        "            if self.config.verbose:\n",
        "                if step % self.config.verbose_step == 0:\n",
        "                    xm.master_print(\n",
        "                        f'Valid Step {step}, loss: ' + \\\n",
        "                        f'{losses.avg:.5f}, final_score: {final_scores.avg:.5f}, ' + \\\n",
        "                        f'time: {(time.time() - t):.5f}'\n",
        "                    )\n",
        "            with torch.no_grad():\n",
        "                inputs = inputs.to(self.device, dtype=torch.long) \n",
        "                attention_masks = attention_masks.to(self.device, dtype=torch.long) \n",
        "                targets = targets.to(self.device, dtype=torch.float) \n",
        "\n",
        "                outputs = self.model(inputs, attention_masks)\n",
        "                loss = self.criterion(outputs, targets)\n",
        "                \n",
        "                batch_size = inputs.size(0)\n",
        "\n",
        "                final_scores.update(targets, outputs)\n",
        "                losses.update(loss.detach().item(), batch_size)\n",
        "                \n",
        "        return losses, final_scores\n",
        "         \n",
        "    def train_one_epoch(self, train_loader,mode='train'):\n",
        "        self.model.train()\n",
        "\n",
        "        losses = AverageMeter()\n",
        "        final_scores = RocAucMeter()\n",
        "        t = time.time()\n",
        "        for step, (targets, inputs, attention_masks) in enumerate(train_loader):   \n",
        "            if self.config.verbose:\n",
        "                if step % (200 if mode=='train' else self.config.verbose_step) == 0:\n",
        "                    self.log(\n",
        "                        f'Train Step {step}, loss: ' + \\\n",
        "                        f'{losses.avg:.5f}, final_score: {final_scores.avg:.5f}, ' + \\\n",
        "                        f'time: {(time.time() - t):.5f}'\n",
        "                    )\n",
        "\n",
        "            inputs = inputs.to(self.device, dtype=torch.long)\n",
        "            attention_masks = attention_masks.to(self.device, dtype=torch.long)\n",
        "            targets = targets.to(self.device, dtype=torch.float)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            outputs = self.model(inputs, attention_masks)\n",
        "            loss = self.criterion(outputs, targets)\n",
        "\n",
        "            batch_size = inputs.size(0)\n",
        "            \n",
        "            final_scores.update(targets, outputs)\n",
        "            \n",
        "            losses.update(loss.detach().item(), batch_size)\n",
        "\n",
        "            loss.backward()\n",
        "            xm.optimizer_step(self.optimizer)\n",
        "\n",
        "            if self.config.step_scheduler:\n",
        "                self.scheduler.step()\n",
        "        \n",
        "        # self.model.eval()\n",
        "        # self.save(f'{CHECKPOINT_PATH}/last-checkpoint.bin')\n",
        "        return losses, final_scores\n",
        "\n",
        "    def run_inference(self, test_loader,postfix='test'):\n",
        "        self.model.eval()\n",
        "        result = {'id': [], 'toxic': []}\n",
        "        t = time.time()\n",
        "        for step, (ids, inputs, attention_masks) in enumerate(test_loader):\n",
        "            if self.config.verbose:\n",
        "                if step % self.config.verbose_step == 0:\n",
        "                    xm.master_print(f'Prediction Step {step}, time: {(time.time() - t):.5f}')\n",
        "\n",
        "            with torch.no_grad():\n",
        "                inputs = inputs.to(self.device, dtype=torch.long) \n",
        "                attention_masks = attention_masks.to(self.device, dtype=torch.long)\n",
        "                outputs = self.model(inputs, attention_masks)\n",
        "                toxics = nn.functional.softmax(outputs, dim=1).data.cpu().numpy()[:,1]\n",
        "\n",
        "            result['id'].extend(ids.cpu().numpy())\n",
        "            result['toxic'].extend(toxics)\n",
        "\n",
        "        result = pd.DataFrame(result)\n",
        "        node_count = len(glob(f'{CHECKPOINT_PATH}/node_submissions/*.csv'))\n",
        "        result.to_csv(f'{CHECKPOINT_PATH}/node_submissions/submission_{node_count}_{datetime.utcnow().microsecond}_{random.random()}_{postfix}.csv', index=False)\n",
        "\n",
        "    def save(self, path):        \n",
        "        xm.save(self.model.state_dict(), path)\n",
        "\n",
        "    def log(self, message):\n",
        "        if self.config.verbose:\n",
        "            xm.master_print(message)\n",
        "        with open(self.log_path, 'a+') as logger:\n",
        "            xm.master_print(f'{message}', logger)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO9ovGhdwb7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import XLMRobertaModel\n",
        "\n",
        "class ToxicSimpleNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self,head='main_head',config=None):\n",
        "        super(ToxicSimpleNNModel, self).__init__()\n",
        "        self.config = config\n",
        "        self.head=head\n",
        "        self.backbone = XLMRobertaModel.from_pretrained(BACKBONE_PATH, config=config)\n",
        "        if head == 'head0':\n",
        "          self.dropout = nn.Dropout(0.3)\n",
        "          self.linear = nn.Linear(\n",
        "              in_features=self.backbone.pooler.dense.out_features * 2,\n",
        "              out_features=2,\n",
        "          )\n",
        "        elif head == 'cnn_head':\n",
        "          self.dropout = nn.Dropout(0.3)\n",
        "          self.dropout2 = nn.Dropout(0.1)\n",
        "          self.conv_head = nn.Conv1d(self.backbone.pooler.dense.out_features, 64, 1, padding=0, padding_mode='zeros')\n",
        "          self.linear = nn.Linear(\n",
        "              in_features=64 * 2,\n",
        "              out_features=2,\n",
        "          )\n",
        "        elif head == 'head1':\n",
        "          self.dropout = nn.Dropout(0.3)\n",
        "          self.linear = nn.Linear(\n",
        "              in_features=self.backbone.pooler.dense.out_features * 6,\n",
        "              out_features=2,\n",
        "          )   \n",
        "        elif head == 'head2':\n",
        "          self.dropout = nn.Dropout(0.3)\n",
        "          self.linear = nn.Linear(\n",
        "              in_features=self.backbone.pooler.dense.out_features * 2,\n",
        "              out_features=config.num_labels\n",
        "          )\n",
        "        elif head == 'head1_1':\n",
        "          self.dropout = nn.Dropout(0.3)\n",
        "          self.linear = nn.Linear(\n",
        "              in_features=self.backbone.pooler.dense.out_features * 6,\n",
        "              out_features=config.num_labels\n",
        "          )\n",
        "        elif head == 'cnn_head2':\n",
        "          self.dropout = nn.Dropout(0.3)\n",
        "          self.dropout2 = nn.Dropout(0.1)\n",
        "          self.conv_head = nn.Conv1d(self.backbone.pooler.dense.out_features*3, 128, 1, padding=0, padding_mode='zeros')\n",
        "          self.linear = nn.Linear(\n",
        "              in_features=128 * 2,\n",
        "              out_features=config.num_labels,\n",
        "          )\n",
        "        else:\n",
        "          raise ValueError(f'no such head {head}')     \n",
        "    def forward(self, input_ids, attention_masks):\n",
        "        bs, seq_length = input_ids.shape\n",
        "        seq_x, _,hidden = self.backbone(input_ids=input_ids, attention_mask=attention_masks)\n",
        "        if self.head=='head0' or self.head=='head2':\n",
        "          apool = torch.mean(seq_x, 1)\n",
        "          mpool, _ = torch.max(seq_x, 1)\n",
        "          x = torch.cat((apool, mpool), 1)\n",
        "          x = self.dropout(x)\n",
        "          return self.linear(x)\n",
        "        elif self.head=='cnn_head':\n",
        "\n",
        "          seq_x = seq_x.permute(0, 2, 1)      # (batch, 64,224)\n",
        "          seq_x = self.conv_head(self.dropout2(seq_x)).permute(0, 2, 1) # (batch, 224, 64)\n",
        "          apool = torch.mean(seq_x, 1) # (batch, 64)\n",
        "          mpool, _ = torch.max(seq_x, 1) # (batch, 64)\n",
        "          x = torch.cat((apool, mpool), 1) # (batch, 64 * 2)\n",
        "\n",
        "          x = self.dropout(x)\n",
        "          return self.linear(x) # (batch, 1)\n",
        "        elif self.head=='head1' or self.head == 'head1_1':\n",
        "          seq_x = torch.cat((hidden[-1], hidden[-2], hidden[-3]), dim=-1)\n",
        "          apool = torch.mean(seq_x, 1)\n",
        "          mpool, _ = torch.max(seq_x, 1)\n",
        "          x = torch.cat((apool, mpool), 1)\n",
        "          x = self.dropout(seq_x)\n",
        "        elif self.head=='cnn_head2':\n",
        "          \n",
        "          seq_x = torch.cat((hidden[-1], hidden[-2], hidden[-3]), dim=-1)\n",
        "          seq_x = seq_x.permute(0, 2, 1)      # (batch, 64,224)\n",
        "          seq_x = self.conv_head(self.dropout2(seq_x)).permute(0, 2, 1) # (batch, 224, 64)\n",
        "          apool = torch.mean(seq_x, 1) # (batch, 64)\n",
        "          mpool, _ = torch.max(seq_x, 1) # (batch, 64)\n",
        "          x = torch.cat((apool, mpool), 1) # (batch, 64 * 2)\n",
        "\n",
        "          x = self.dropout(x)\n",
        "          return self.linear(x) # (batch, 1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZmTJ4XQwb9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainGlobalConfig:\n",
        "    \"\"\" Global Config for this notebook \"\"\"\n",
        "    num_workers = 0  # количество воркеров для loaders\n",
        "    batch_size = 16  # bs\n",
        "    n_epochs = 1  # количество эпох для обучения\n",
        "    lr = 0.5 * 1e-5 # стартовый learning rate (внутри логика работы с мульти TPU домножает на кол-во процессов)\n",
        "    fold_number = 0  # номер фолда для обучения\n",
        "    valid_n_epochs=2\n",
        "    # -------------------\n",
        "    verbose = True  # выводить принты\n",
        "    verbose_step = 50  # количество шагов для вывода принта\n",
        "    # -------------------\n",
        "\n",
        "    # --------------------\n",
        "    step_scheduler = False  # выполнять scheduler.step после вызова optimizer.step\n",
        "    validation_scheduler = True  # выполнять scheduler.step после валидации loss (например для плато)\n",
        "    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
        "    scheduler_params = dict(\n",
        "        mode='max',\n",
        "        factor=0.7,\n",
        "        patience=0,\n",
        "        verbose=False, \n",
        "        threshold=0.0001,\n",
        "        threshold_mode='abs',\n",
        "        cooldown=0, \n",
        "        min_lr=1e-8,\n",
        "        eps=1e-08\n",
        "    )\n",
        "    # --------------------\n",
        "\n",
        "    # -------------------\n",
        "    criterion = LabelSmoothing()\n",
        "    # -------------------"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_79qoceFwcAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_config = XLMRobertaConfig.from_pretrained('/content/drive/My Drive/Colab Notebooks/toxic_multi/xlm-roberta-large')\n",
        "bert_config.output_hidden_states = True\n",
        "bert_config.num_labels = 2\n",
        "net = ToxicSimpleNNModel(config=bert_config,head='cnn_head2')\n",
        "\n",
        "checkpoint = torch.load(f'{CHECKPOINT_PATH}/best_model.bin', map_location=torch.device('cpu'))\n",
        "net.load_state_dict(checkpoint);\n",
        "\n",
        "checkpoint = None\n",
        "del checkpoint\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INecI_CbxXA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _mp_pr_fn(rank, flags):\n",
        "    device = xm.xla_device()\n",
        "    model = net.to(device)\n",
        "\n",
        "    test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        test_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=16,\n",
        "        sampler=test_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=1\n",
        "    )\n",
        "\n",
        "    fitter = MultiTPUPredictor(model=model, device=device)\n",
        "    fitter.run_inference(test_loader)\n",
        "def _mp_fn_fold_valid(rank, flags,i):\n",
        "  \n",
        "\n",
        "    # net = ToxicSimpleNNModel(config=bert_config,head='cnn_head2')\n",
        "\n",
        "    \n",
        "    # net.load_state_dict(checkpoint)\n",
        "    # checkpoint = None\n",
        "    # del checkpoint\n",
        "\n",
        "    device = xm.xla_device()\n",
        "    # i= 0\n",
        "\n",
        "    net.to(device)\n",
        "      # checkpoint = torch.load(f'{CHECKPOINT_PATH}/best_model.bin', map_location=torch.device('cpu'))\n",
        "\n",
        "    train_sampler = DistributedSamplerWrapper(\n",
        "        sampler=RandomSampler(val_train_fd[i]),\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=True\n",
        "    )\n",
        "    valid_train_loader = torch.utils.data.DataLoader(\n",
        "      val_train_fd[i],\n",
        "      batch_size=TrainGlobalConfig.batch_size,\n",
        "      sampler=train_sampler,\n",
        "      pin_memory=False,\n",
        "      drop_last=True,\n",
        "      num_workers=TrainGlobalConfig.num_workers)\n",
        "\n",
        "    train_en_sampler = DistributedSamplerWrapper(\n",
        "        sampler=RandomSampler(val_train_en_fd[i]),\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=True\n",
        "    )\n",
        "    valid_train_en_loader = torch.utils.data.DataLoader(\n",
        "      val_train_en_fd[i],\n",
        "      batch_size=TrainGlobalConfig.batch_size,\n",
        "      sampler=train_en_sampler,\n",
        "      pin_memory=False,\n",
        "      drop_last=True,\n",
        "      num_workers=TrainGlobalConfig.num_workers)\n",
        "    \n",
        "    validation_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        val_valid_fd[i],\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False\n",
        "    )\n",
        "    valid_test_loader = torch.utils.data.DataLoader(\n",
        "        val_valid_fd[i],\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=validation_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=TrainGlobalConfig.num_workers\n",
        "    )\n",
        "\n",
        "    validation_en_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        val_valid_en_fd[i],\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False\n",
        "    )\n",
        "    valid_en_test_loader = torch.utils.data.DataLoader(\n",
        "        val_valid_en_fd[i],\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=validation_en_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=TrainGlobalConfig.num_workers\n",
        "    )\n",
        "\n",
        "    validation_infe_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        val_inf_fd[i], #val_inf_fd,val_en_inf_fd\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    valid_infe_loader = torch.utils.data.DataLoader(\n",
        "        val_inf_fd[i], #val_inf_fd,val_en_inf_fd\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=validation_infe_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=TrainGlobalConfig.num_workers\n",
        "    )\n",
        "\n",
        "\n",
        "    test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        test_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False\n",
        "    )\n",
        "    test_en_loader = torch.utils.data.DataLoader(\n",
        "        test_en_dataset,\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=test_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=TrainGlobalConfig.num_workers\n",
        "    )\n",
        "    test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        test_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=test_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=TrainGlobalConfig.num_workers\n",
        "    )\n",
        "    fitter = TPUFitter(model=net, device=device, config=TrainGlobalConfig)\n",
        "    \n",
        "    # fitter.fit_valid(valid_train_en_loader, valid_en_test_loader,i)\n",
        "    fitter.fit_valid(valid_train_loader, valid_test_loader,i)\n",
        "    fitter.run_inference(test_loader,postfix='test')\n",
        "    fitter.run_inference(valid_infe_loader,postfix='valid')\n",
        "    # tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "def _mp_fn(rank, flags):\n",
        "    device = xm.xla_device()\n",
        "    net.to(device)\n",
        "\n",
        "    train_sampler = DistributedSamplerWrapper(\n",
        "        sampler=BalanceClassSampler(labels=train_dataset.get_labels(), mode=\"downsampling\"),\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=True\n",
        "    )\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=train_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=True,\n",
        "        num_workers=TrainGlobalConfig.num_workers,\n",
        "    )\n",
        "    validation_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        validation_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False\n",
        "    )\n",
        "    validation_loader = torch.utils.data.DataLoader(\n",
        "        validation_dataset,\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=validation_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=TrainGlobalConfig.num_workers\n",
        "    )\n",
        "    validation_tune_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        validation_tune_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=True\n",
        "    )\n",
        "    validation_tune_loader = torch.utils.data.DataLoader(\n",
        "        validation_tune_dataset,\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=validation_tune_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=TrainGlobalConfig.num_workers\n",
        "    )\n",
        "    validation_infer_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        validation_all_infer_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False\n",
        "    )\n",
        "    validation_infe_loader = torch.utils.data.DataLoader(\n",
        "        validation_all_infer_dataset,\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=validation_infer_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=TrainGlobalConfig.num_workers\n",
        "    )\n",
        "    test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        test_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=test_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=TrainGlobalConfig.num_workers\n",
        "    )\n",
        "    test_en_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        test_en_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False\n",
        "    )\n",
        "    test_en_loader = torch.utils.data.DataLoader(\n",
        "        test_en_dataset,\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=test_en_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=TrainGlobalConfig.num_workers\n",
        "    )\n",
        "    if rank == 0:\n",
        "        time.sleep(1)\n",
        "    \n",
        "    fitter = TPUFitter(model=net, device=device, config=TrainGlobalConfig)\n",
        "    fitter.fit(train_loader, validation_loader)\n",
        "    # fitter.run_tuning_and_inference(test_loader, validation_tune_loader)\n",
        "    # fitter.run_inference(validation_infe_loader)\n",
        "    # fitter.run_inference(test_en_loader,postfix='test')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N92Crh8tWRuy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "4632b673-b122-4fe2-a1ab-ac236ca7aabd"
      },
      "source": [
        "FLAGS={}\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model prepared. Device is xla:1\n",
            "Fitter prepared. Device is xla:1\n",
            "\n",
            "2020-06-19T02:03:16.100803\n",
            "LR: 4e-05\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 1.61779\n",
            "Train Step 200, loss: 0.30583, final_score: 0.98192, time: 325.14355\n",
            "Train Step 400, loss: 0.30417, final_score: 0.98195, time: 581.92780\n",
            "Train Step 600, loss: 0.30229, final_score: 0.98254, time: 838.44405\n",
            "Train Step 800, loss: 0.30428, final_score: 0.98171, time: 1094.01948\n",
            "Train Step 1000, loss: 0.30393, final_score: 0.98165, time: 1351.49991\n",
            "Train Step 1200, loss: 0.30549, final_score: 0.98118, time: 1608.79916\n",
            "Train Step 1400, loss: 0.30904, final_score: 0.98011, time: 1864.80965\n",
            "Train Step 1600, loss: 0.30899, final_score: 0.98026, time: 2122.75808\n",
            "Train Step 1800, loss: 0.30851, final_score: 0.98043, time: 2378.21862\n",
            "Train Step 2000, loss: 0.30809, final_score: 0.98058, time: 2635.14308\n",
            "Train Step 2200, loss: 0.30739, final_score: 0.98081, time: 2892.69401\n",
            "Train Step 2400, loss: 0.30710, final_score: 0.98086, time: 3150.65484\n",
            "Train Step 2600, loss: 0.30669, final_score: 0.98103, time: 3408.48446\n",
            "Train Step 2800, loss: 0.30607, final_score: 0.98130, time: 3668.66830\n",
            "[RESULT]: Train. Epoch: 0, loss: 0.30563, final_score: 0.98140, time: 3885.77605\n",
            "Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.04793\n",
            "Valid Step 50, loss: 0.43078, final_score: 0.94775, time: 23.78124\n",
            "[RESULT]: Validation. Epoch: 0, loss: 0.42855, final_score: 0.94871, time: 30.23845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STckswIlZrHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "8144f90a-56d7-4118-d6bf-ffd0cd91374c"
      },
      "source": [
        "submission = pd.concat([pd.read_csv(path) for path in glob(f'{CHECKPOINT_PATH}/node_submissions/*.csv')]).groupby('id').mean()\n",
        "submission['toxic'].hist(bins=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fed8dadf438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKPY4D4_a8Xh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "0d8004a5-0583-49e1-f3cf-a51f08e2785f"
      },
      "source": [
        "submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.835938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.306641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.906250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.053467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.060059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>0.047607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>0.968750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>0.933594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>0.050293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>0.071289</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         toxic\n",
              "id            \n",
              "0     0.835938\n",
              "1     0.306641\n",
              "2     0.906250\n",
              "3     0.053467\n",
              "4     0.060059\n",
              "...        ...\n",
              "7995  0.047607\n",
              "7996  0.968750\n",
              "7997  0.933594\n",
              "7998  0.050293\n",
              "7999  0.071289\n",
              "\n",
              "[8000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qoGkD6TVwJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name='cnn_head2_0618_jigsaw1_2Tran_jigsaw1test'\n",
        "val_lang='raw'\n",
        "test_lang='raw'"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7H9ZSlC97i7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  del net\n",
        "  torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKuUULH7l5W1",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e848f91-1b22-47a1-de16-73a0bd133db2"
      },
      "source": [
        "\n",
        "bert_config = XLMRobertaConfig.from_pretrained('/content/drive/My Drive/Colab Notebooks/toxic_multi/xlm-roberta-large')\n",
        "bert_config.output_hidden_states = True\n",
        "bert_config.num_labels = 2\n",
        "for i in range(4):\n",
        "  FLAGS={}\n",
        "  # xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')\n",
        "\n",
        "  net = ToxicSimpleNNModel(config=bert_config,head='cnn_head2')\n",
        "  checkpoint = torch.load(f'{CHECKPOINT_PATH}/best_model.bin', map_location=torch.device('cpu'))\n",
        "  net.load_state_dict(checkpoint)\n",
        "  xmp.spawn(_mp_fn_fold_valid,args=(FLAGS,i,), nprocs=8, start_method='fork')\n",
        "  del net\n",
        "  torch.cuda.empty_cache()\n",
        "  submission = pd.concat([pd.read_csv(path) for path in glob(f'{CHECKPOINT_PATH}/node_submissions/*_test.csv')]).groupby('id').mean()\n",
        "  submission2 = pd.concat([pd.read_csv(path) for path in glob(f'{CHECKPOINT_PATH}/node_submissions/*_valid.csv')]).groupby('id').mean()\n",
        "  submission.to_csv(f'{ROOT_PATH}/{model_name}_f{i}_test_{test_lang}.csv')\n",
        "  submission2.to_csv(f'{ROOT_PATH}/{model_name}_f{i}_valid_{val_lang}.csv')\n",
        "  shutil.rmtree(f'{CHECKPOINT_PATH}/node_submissions')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model prepared. Device is xla:1\n",
            "Fitter prepared. Device is xla:1\n",
            "training fold 0\n",
            "\n",
            "\n",
            "2020-06-19T03:13:19.605916\n",
            "LR: 4e-05\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.74721\n",
            "[RESULT]: Train. Epoch: 0, loss: 0.32360, final_score: 0.94475, time: 110.76740\n",
            "Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.74682\n",
            "best score with 0.9641734758013828 for 0\n",
            "[RESULT]: Validation. Epoch: 0, loss: 0.31324, final_score: 0.96417, time: 42.14141\n",
            "\n",
            "2020-06-19T03:15:52.541043\n",
            "LR: 4e-05\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.11041\n",
            "[RESULT]: Train. Epoch: 1, loss: 0.30978, final_score: 0.96929, time: 58.72903\n",
            "Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.74557\n",
            "best score with 0.9678189817724702 for 0\n",
            "[RESULT]: Validation. Epoch: 1, loss: 0.31605, final_score: 0.96782, time: 7.90768\n",
            "Prediction Step 0, time: 0.01060\n",
            "Prediction Step 50, time: 21.57652\n",
            "Prediction Step 100, time: 30.96727\n",
            "Prediction Step 150, time: 40.35389\n",
            "Prediction Step 200, time: 49.79643\n",
            "Prediction Step 250, time: 59.09652\n",
            "Prediction Step 300, time: 68.43482\n",
            "Prediction Step 350, time: 77.74907\n",
            "Prediction Step 400, time: 87.04137\n",
            "Prediction Step 450, time: 96.34239\n",
            "Prediction Step 0, time: 0.00756\n",
            "Model prepared. Device is xla:1\n",
            "Fitter prepared. Device is xla:1\n",
            "training fold 1\n",
            "\n",
            "\n",
            "2020-06-19T03:21:47.546249\n",
            "LR: 4e-05\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.53678\n",
            "[RESULT]: Train. Epoch: 0, loss: 0.32868, final_score: 0.93832, time: 71.90747\n",
            "Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.72391\n",
            "best score with 0.9752468729427255 for 1\n",
            "[RESULT]: Validation. Epoch: 0, loss: 0.28651, final_score: 0.97525, time: 8.71028\n",
            "\n",
            "2020-06-19T03:23:08.185197\n",
            "LR: 4e-05\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.08641\n",
            "[RESULT]: Train. Epoch: 1, loss: 0.28745, final_score: 0.97395, time: 58.16323\n",
            "Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.73468\n",
            "best score with 0.9791968400263331 for 1\n",
            "[RESULT]: Validation. Epoch: 1, loss: 0.28255, final_score: 0.97920, time: 7.82877\n",
            "Prediction Step 0, time: 0.01007\n",
            "Prediction Step 50, time: 10.04203\n",
            "Prediction Step 100, time: 19.31790\n",
            "Prediction Step 150, time: 28.59315\n",
            "Prediction Step 200, time: 37.84094\n",
            "Prediction Step 250, time: 47.09860\n",
            "Prediction Step 300, time: 56.39408\n",
            "Prediction Step 350, time: 65.67393\n",
            "Prediction Step 400, time: 74.94736\n",
            "Prediction Step 450, time: 84.29056\n",
            "Prediction Step 0, time: 0.00714\n",
            "Model prepared. Device is xla:1\n",
            "Fitter prepared. Device is xla:1\n",
            "training fold 2\n",
            "\n",
            "\n",
            "2020-06-19T03:28:01.500725\n",
            "LR: 4e-05\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.47057\n",
            "[RESULT]: Train. Epoch: 0, loss: 0.32409, final_score: 0.95067, time: 63.68652\n",
            "Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.75032\n",
            "best score with 0.9598420013166556 for 2\n",
            "[RESULT]: Validation. Epoch: 0, loss: 0.30870, final_score: 0.95984, time: 8.72802\n",
            "\n",
            "2020-06-19T03:29:13.935703\n",
            "LR: 4e-05\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.08101\n",
            "[RESULT]: Train. Epoch: 1, loss: 0.29322, final_score: 0.97312, time: 58.53198\n",
            "Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.75299\n",
            "best score with 0.9641869651086241 for 2\n",
            "[RESULT]: Validation. Epoch: 1, loss: 0.30088, final_score: 0.96419, time: 7.90638\n",
            "Prediction Step 0, time: 0.00954\n",
            "Prediction Step 50, time: 9.62929\n",
            "Prediction Step 100, time: 19.00088\n",
            "Prediction Step 150, time: 28.80850\n",
            "Prediction Step 200, time: 39.09905\n",
            "Prediction Step 250, time: 48.52483\n",
            "Prediction Step 300, time: 57.95271\n",
            "Prediction Step 350, time: 67.38715\n",
            "Prediction Step 400, time: 76.80358\n",
            "Prediction Step 450, time: 86.24162\n",
            "Prediction Step 0, time: 0.00617\n",
            "Model prepared. Device is xla:1\n",
            "Fitter prepared. Device is xla:1\n",
            "training fold 3\n",
            "\n",
            "\n",
            "2020-06-19T03:34:05.249044\n",
            "LR: 4e-05\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.48380\n",
            "[RESULT]: Train. Epoch: 0, loss: 0.33216, final_score: 0.94423, time: 105.85378\n",
            "Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.78033\n",
            "best score with 0.9661221590909091 for 3\n",
            "[RESULT]: Validation. Epoch: 0, loss: 0.29508, final_score: 0.96612, time: 8.75710\n",
            "\n",
            "2020-06-19T03:35:59.882776\n",
            "LR: 4e-05\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.09161\n",
            "[RESULT]: Train. Epoch: 1, loss: 0.31825, final_score: 0.96308, time: 58.70910\n",
            "Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.73301\n",
            "best score with 0.9732954545454545 for 3\n",
            "[RESULT]: Validation. Epoch: 1, loss: 0.29213, final_score: 0.97330, time: 7.91701\n",
            "Prediction Step 0, time: 0.01290\n",
            "Prediction Step 50, time: 9.58155\n",
            "Prediction Step 100, time: 18.91589\n",
            "Prediction Step 150, time: 28.17190\n",
            "Prediction Step 200, time: 37.43523\n",
            "Prediction Step 250, time: 46.77767\n",
            "Prediction Step 300, time: 56.14892\n",
            "Prediction Step 350, time: 65.48949\n",
            "Prediction Step 400, time: 74.80915\n",
            "Prediction Step 450, time: 84.07851\n",
            "Prediction Step 0, time: 0.00647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui-UAFUBDiGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.concat([pd.read_csv(f'{ROOT_PATH}/{model_name}_f{i}_valid_{val_lang}.csv') for i in range(4)])\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu0VhhZAFuYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d901bcf4-c1ee-4518-c43e-039c85bbb0b7"
      },
      "source": [
        "# submission = pd.concat([pd.read_csv(path) for path in glob(f'{CHECKPOINT_PATH}/node_submissions/*_0_*_test.csv')]).groupby('id').mean()\n",
        "submission['toxic'].hist(bins=100)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff5599125c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYp19N0CEl8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = submission.sort_values(by='id').reset_index(drop=True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p51rwnoxID1Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "c830866b-9fb0-4e5d-b4e6-e82d4769a91c"
      },
      "source": [
        "submission"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.140625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.070312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.753906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.035645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.030029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>7995</td>\n",
              "      <td>0.030151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>7996</td>\n",
              "      <td>0.957031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>7997</td>\n",
              "      <td>0.859375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>7998</td>\n",
              "      <td>0.028442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>7999</td>\n",
              "      <td>0.036133</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id     toxic\n",
              "0        0  0.140625\n",
              "1        1  0.070312\n",
              "2        2  0.753906\n",
              "3        3  0.035645\n",
              "4        4  0.030029\n",
              "...    ...       ...\n",
              "7995  7995  0.030151\n",
              "7996  7996  0.957031\n",
              "7997  7997  0.859375\n",
              "7998  7998  0.028442\n",
              "7999  7999  0.036133\n",
              "\n",
              "[8000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o18AiM-5Ccf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.sort_values(by='id').reset_index(drop=True).to_csv(f'{ROOT_PATH}/{model_name}_valid_{val_lang}.csv',index=False)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiWNCNJ8EQps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val = pd.read_csv(f'{ROOT_PATH}/input/validation.csv', index_col='id')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTQvg7oKESjb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ed9edc8-8f5b-48d3-96ad-dc4ef60deaef"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(val['toxic'],submission['toxic'])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.952560975609756"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkxUZhTOIBaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "20cdf819-927c-455c-dc84-6c4d723d09ae"
      },
      "source": [
        "\n",
        "df_val = pd.read_csv(f'{ROOT_PATH}/input/validation.csv', index_col='id')\n",
        "\n",
        "for fold, (trn_idx, val_idx) in enumerate(kf.split(X=df_val,y=df_val[['lang','toxic']].values)):\n",
        "  print(fold,roc_auc_score(df_val.loc[val_idx,'toxic'],submission.loc[val_idx,'toxic']))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.9497242562402136\n",
            "1 0.9602157594178871\n",
            "2 0.950160750051467\n",
            "3 0.9522896540843595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzOzZA4QOGck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = None\n",
        "for i in range(4):\n",
        "  temp = pd.read_csv(f'{ROOT_PATH}/{model_name}_f{i}_test_{test_lang}.csv').rename(columns = {'toxic':f'toxic_f{i}'})\n",
        "  if preds is None:\n",
        "    preds = temp\n",
        "  else:\n",
        "    preds = preds.merge(temp,on='id',how='inner')\n",
        "  "
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiCESmj4Ok5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds['toxic'] = preds[['toxic_f0','toxic_f1','toxic_f2','toxic_f3']].mean(axis=1)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgF3n5XOenOW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "5c3a9f98-bc32-4121-8358-5afc13922d6a"
      },
      "source": [
        "preds['toxic'].hist(bins=100)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff5588270b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPMuO-_GerJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "7cc938c1-fec2-4c05-c22c-6bb6e562510d"
      },
      "source": [
        "preds"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic_f0</th>\n",
              "      <th>toxic_f1</th>\n",
              "      <th>toxic_f2</th>\n",
              "      <th>toxic_f3</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.030640</td>\n",
              "      <td>0.030396</td>\n",
              "      <td>0.031738</td>\n",
              "      <td>0.027954</td>\n",
              "      <td>0.030182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.149414</td>\n",
              "      <td>0.043945</td>\n",
              "      <td>0.039307</td>\n",
              "      <td>0.111328</td>\n",
              "      <td>0.085999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.300781</td>\n",
              "      <td>0.300781</td>\n",
              "      <td>0.306641</td>\n",
              "      <td>0.206055</td>\n",
              "      <td>0.278564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.032227</td>\n",
              "      <td>0.029785</td>\n",
              "      <td>0.031982</td>\n",
              "      <td>0.026489</td>\n",
              "      <td>0.030121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.035645</td>\n",
              "      <td>0.033203</td>\n",
              "      <td>0.035645</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0.033936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63807</th>\n",
              "      <td>63807</td>\n",
              "      <td>0.135742</td>\n",
              "      <td>0.109375</td>\n",
              "      <td>0.089844</td>\n",
              "      <td>0.072266</td>\n",
              "      <td>0.101807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63808</th>\n",
              "      <td>63808</td>\n",
              "      <td>0.033203</td>\n",
              "      <td>0.031982</td>\n",
              "      <td>0.035645</td>\n",
              "      <td>0.029297</td>\n",
              "      <td>0.032532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63809</th>\n",
              "      <td>63809</td>\n",
              "      <td>0.076172</td>\n",
              "      <td>0.068359</td>\n",
              "      <td>0.053955</td>\n",
              "      <td>0.049316</td>\n",
              "      <td>0.061951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63810</th>\n",
              "      <td>63810</td>\n",
              "      <td>0.032471</td>\n",
              "      <td>0.036133</td>\n",
              "      <td>0.032227</td>\n",
              "      <td>0.029053</td>\n",
              "      <td>0.032471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63811</th>\n",
              "      <td>63811</td>\n",
              "      <td>0.027710</td>\n",
              "      <td>0.028809</td>\n",
              "      <td>0.030396</td>\n",
              "      <td>0.027100</td>\n",
              "      <td>0.028503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63812 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  toxic_f0  toxic_f1  toxic_f2  toxic_f3     toxic\n",
              "0          0  0.030640  0.030396  0.031738  0.027954  0.030182\n",
              "1          1  0.149414  0.043945  0.039307  0.111328  0.085999\n",
              "2          2  0.300781  0.300781  0.306641  0.206055  0.278564\n",
              "3          3  0.032227  0.029785  0.031982  0.026489  0.030121\n",
              "4          4  0.035645  0.033203  0.035645  0.031250  0.033936\n",
              "...      ...       ...       ...       ...       ...       ...\n",
              "63807  63807  0.135742  0.109375  0.089844  0.072266  0.101807\n",
              "63808  63808  0.033203  0.031982  0.035645  0.029297  0.032532\n",
              "63809  63809  0.076172  0.068359  0.053955  0.049316  0.061951\n",
              "63810  63810  0.032471  0.036133  0.032227  0.029053  0.032471\n",
              "63811  63811  0.027710  0.028809  0.030396  0.027100  0.028503\n",
              "\n",
              "[63812 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRr-yzJ_yVTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds[['id','toxic']].to_csv(f'{ROOT_PATH}/{model_name}_test_{test_lang}.csv',index=False)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4d_Z4K9Uwmy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "0b7f1a27-dbb7-4d25-d224-1c15a199a6a1"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic_f0</th>\n",
              "      <th>toxic_f1</th>\n",
              "      <th>toxic_f2</th>\n",
              "      <th>toxic_f3</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.039795</td>\n",
              "      <td>0.050293</td>\n",
              "      <td>0.041992</td>\n",
              "      <td>0.041992</td>\n",
              "      <td>0.043518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.106934</td>\n",
              "      <td>0.106934</td>\n",
              "      <td>0.044678</td>\n",
              "      <td>0.101074</td>\n",
              "      <td>0.089905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.281250</td>\n",
              "      <td>0.453125</td>\n",
              "      <td>0.371094</td>\n",
              "      <td>0.244141</td>\n",
              "      <td>0.337402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.044678</td>\n",
              "      <td>0.056641</td>\n",
              "      <td>0.037354</td>\n",
              "      <td>0.047607</td>\n",
              "      <td>0.046570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.044678</td>\n",
              "      <td>0.053467</td>\n",
              "      <td>0.037354</td>\n",
              "      <td>0.037354</td>\n",
              "      <td>0.043213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63807</th>\n",
              "      <td>63807</td>\n",
              "      <td>0.122559</td>\n",
              "      <td>0.207031</td>\n",
              "      <td>0.115723</td>\n",
              "      <td>0.112793</td>\n",
              "      <td>0.139526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63808</th>\n",
              "      <td>63808</td>\n",
              "      <td>0.050293</td>\n",
              "      <td>0.060059</td>\n",
              "      <td>0.041992</td>\n",
              "      <td>0.039795</td>\n",
              "      <td>0.048035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63809</th>\n",
              "      <td>63809</td>\n",
              "      <td>0.075684</td>\n",
              "      <td>0.106934</td>\n",
              "      <td>0.056641</td>\n",
              "      <td>0.067871</td>\n",
              "      <td>0.076782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63810</th>\n",
              "      <td>63810</td>\n",
              "      <td>0.044678</td>\n",
              "      <td>0.067871</td>\n",
              "      <td>0.039795</td>\n",
              "      <td>0.041992</td>\n",
              "      <td>0.048584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63811</th>\n",
              "      <td>63811</td>\n",
              "      <td>0.041992</td>\n",
              "      <td>0.053467</td>\n",
              "      <td>0.037354</td>\n",
              "      <td>0.041992</td>\n",
              "      <td>0.043701</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63812 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  toxic_f0  toxic_f1  toxic_f2  toxic_f3     toxic\n",
              "0          0  0.039795  0.050293  0.041992  0.041992  0.043518\n",
              "1          1  0.106934  0.106934  0.044678  0.101074  0.089905\n",
              "2          2  0.281250  0.453125  0.371094  0.244141  0.337402\n",
              "3          3  0.044678  0.056641  0.037354  0.047607  0.046570\n",
              "4          4  0.044678  0.053467  0.037354  0.037354  0.043213\n",
              "...      ...       ...       ...       ...       ...       ...\n",
              "63807  63807  0.122559  0.207031  0.115723  0.112793  0.139526\n",
              "63808  63808  0.050293  0.060059  0.041992  0.039795  0.048035\n",
              "63809  63809  0.075684  0.106934  0.056641  0.067871  0.076782\n",
              "63810  63810  0.044678  0.067871  0.039795  0.041992  0.048584\n",
              "63811  63811  0.041992  0.053467  0.037354  0.041992  0.043701\n",
              "\n",
              "[63812 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1oxax9JyVXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "shutil.rmtree(f'{CHECKPOINT_PATH}/node_submissions')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8K3-V7nfsUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}